{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 인스타그램 크롤링 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 인스타그램 검색 결과 URL을 만들어서 접속하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-1 인스타그램 검색결과 URL을 만드는 함수\n",
    "def insta_searching(word):\n",
    "    url = \"https://www.instagram.com/explore/tags/\" + word\n",
    "    return url\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-2 selenium으로 URL 접속하기 - 1\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-2 selenium으로 URL 접속하기 - 2\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# 인스타그램 접속하기\n",
    "driver.get('https://www.instagram.com/')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-2 selenium으로 URL 접속하기 - 3\n",
    "\n",
    "# HTML 틀 바뀌어서 찾아서 변경함.\n",
    "# 인스타계정으로 로그인하기\n",
    "email = '01041303038'   ### 계정 정보 수정 필요\n",
    "password = 'moonwalk486!' ### 비번 정보 수정 필요\n",
    "\n",
    "# 인스타그램 로그인 버튼 클릭\n",
    "driver.find_element(By.CLASS_NAME, '_aa4b ').click()\n",
    "time.sleep(2)\n",
    "\n",
    "# 이메일 입력란 찾아서 값 입력\n",
    "email_input = driver.find_element(By.CLASS_NAME, '_aa4b')\n",
    "email_input.send_keys(email)\n",
    "\n",
    "# 비밀번호 입력란 찾아서 값 입력\n",
    "password_input = driver.find_elements(By.CLASS_NAME, '_aa4b')[1] \n",
    "password_input.send_keys(password)\n",
    "\n",
    "# 로그인 버튼 클릭\n",
    "login_button = driver.find_element(By.CSS_SELECTOR, 'button[type=\"submit\"]')\n",
    "login_button.click()\n",
    "\n",
    "# 일부 웹사이트에서는 로그인 버튼의 클릭 후 잠시 대기가 필요할 수 있습니다.\n",
    "time.sleep(2)  # 예시로 2초 대기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-2 selenium으로 URL 접속하기 - 4\n",
    "word = \"김채원\"\n",
    "url = insta_searching(word)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 첫 번째 게시글 열기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-3 HTML에서 첫번째 게시글 찾아 클릭하기\n",
    "\n",
    "# 내용 일부 수정\n",
    "def select_first(driver):\n",
    "    first = driver.find_element(By.CSS_SELECTOR, \"div._aagw\")\n",
    "    first.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "select_first(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 게시글 정보 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['03/03 채원이 인스타 게시물❤️너무 이쁘다아….🫢❤️#kimchaewon #chaewon #lesserafim #fearnot #김채원 #채원 #러블리더 #아기치타 #채채 #푸푸 #쌈무 #쌈아치 #쌈무요정 #모닝채원 #김도독 #핌둥이 #피어나 #르세라핌 #キムチェウォン #ルセラフィム',\n",
       " '2024-03-03',\n",
       " '1247',\n",
       " '',\n",
       " ['#kimchaewon ',\n",
       "  '#chaewon ',\n",
       "  '#le',\n",
       "  '#fearnot ',\n",
       "  '#김채원 ',\n",
       "  '#채원 ',\n",
       "  '#러블리더 ',\n",
       "  '#아기치타 ',\n",
       "  '#채채 ',\n",
       "  '#푸푸 ',\n",
       "  '#쌈무 ',\n",
       "  '#쌈아치 ',\n",
       "  '#쌈무요정 ',\n",
       "  '#모닝채원 ',\n",
       "  '#김도독 ',\n",
       "  '#핌둥이 ',\n",
       "  '#피어나 ',\n",
       "  '#르세라핌 ',\n",
       "  '#キムチェウォン ',\n",
       "  '#ルセラフィム']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 4-4 게시글 정보 가져오기\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "def get_content(driver):\n",
    "    # ① 현재 페이지 html 정보 가져오기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # ② 본문 내용 가져오기\n",
    "    try:\n",
    "        content = soup.select('div._a9zs')[0].text\n",
    "        content = unicodedata.normalize('NFC', content)\n",
    "    except:\n",
    "        content = ' '\n",
    "    \n",
    "    # ③ 본문 내용에서 해시태그 가져오기(정규식 활용)\n",
    "    tags = re.findall(r'#[^Ws#,\\\\]+', content)\n",
    "   \n",
    "    # ④ 작성일자 정보 가져오기\n",
    "    # time class 안에 datetime이라는 항목(년월일시분초 있음)에서 10개 string만 보겠다라는 뜻\n",
    "    date = soup.select('time._a9ze')[0]['datetime'][:10] \n",
    "\n",
    "    # ⑤ 좋아요 수 가져오기\n",
    "    try:\n",
    "        like = soup.select('span.html-span')[2].text\n",
    "    except:\n",
    "        like = 0\n",
    "        \n",
    "    # ⑥ 위치정보 가져오기\n",
    "    try: \n",
    "        place = soup.select('div._aaqm')[0].text\n",
    "        place = unicodedata.normalize('NFC', place)      # 신규 추가. 2020.08.20\n",
    "    except:\n",
    "        place = ''\n",
    "    # ⑦ 수집한 정보 저장하기\n",
    "    data = [content, date, like, place, tags]\n",
    "    return data\n",
    " \n",
    "get_content(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 다음 게시글 열기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-5 다음 게시글 열기\n",
    "def move_next(driver):\n",
    "    right = driver.find_element(By.CSS_SELECTOR, \"div._aaqg._aaqh\")\n",
    "    right.click()\n",
    "    time.sleep(4)\n",
    "move_next(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.6 여러 게시글 정보 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['03/03 채원이 인스타 게시물❤️너무 이쁘다아….🫢❤️#kimchaewon #chaewon #lesserafim #fearnot #김채원 #채원 #러블리더 #아기치타 #채채 #푸푸 #쌈무 #쌈아치 #쌈무요정 #모닝채원 #김도독 #핌둥이 #피어나 #르세라핌 #キムチェウォン #ルセラフィム', '2024-03-03', '1247', '', ['#kimchaewon ', '#chaewon ', '#le', '#fearnot ', '#김채원 ', '#채원 ', '#러블리더 ', '#아기치타 ', '#채채 ', '#푸푸 ', '#쌈무 ', '#쌈아치 ', '#쌈무요정 ', '#모닝채원 ', '#김도독 ', '#핌둥이 ', '#피어나 ', '#르세라핌 ', '#キムチェウォン ', '#ルセラフィム']], ['02/23 Weverse 채원이💛피.어.나선.물🧸이런 선물…너무 좋아😍#kimchaewon #chaewon #lesserafim #fearnot #김채원 #채원 #러블리더 #아기치타 #채채 #푸푸 #쌈무 #쌈무요정 #쌈아치 #모닝채원 #김도독 #핌둥이 #피어나 #르세라핌 #キムチェウォン #ルセラフィム', '2024-02-23', '5916', '', ['#kimchaewon ', '#chaewon ', '#le', '#fearnot ', '#김채원 ', '#채원 ', '#러블리더 ', '#아기치타 ', '#채채 ', '#푸푸 ', '#쌈무 ', '#쌈무요정 ', '#쌈아치 ', '#모닝채원 ', '#김도독 ', '#핌둥이 ', '#피어나 ', '#르세라핌 ', '#キムチェウォン ', '#ルセラフィム']]]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = webdriver.Chrome()   \n",
    "\n",
    "# 인스타그램 접속하기\n",
    "driver.get('https://www.instagram.com/')\n",
    "time.sleep(2)\n",
    "\n",
    "# 인스타계정으로 로그인하기\n",
    "email = '01041303038'   \n",
    "password = 'moonwalk486!' \n",
    "\n",
    "# 인스타그램 로그인 버튼 클릭\n",
    "driver.find_element(By.CLASS_NAME, '_aa4b ').click()\n",
    "time.sleep(2)\n",
    "\n",
    "# 이메일 입력란 찾아서 값 입력\n",
    "email_input = driver.find_element(By.CLASS_NAME, '_aa4b')\n",
    "email_input.send_keys(email)\n",
    "\n",
    "# 비밀번호 입력란 찾아서 값 입력\n",
    "password_input = driver.find_elements(By.CLASS_NAME, '_aa4b')[1] \n",
    "password_input.send_keys(password)\n",
    "\n",
    "# 로그인 버튼 클릭\n",
    "login_button = driver.find_element(By.CSS_SELECTOR, 'button[type=\"submit\"]')\n",
    "login_button.click()\n",
    "time.sleep(3)  \n",
    "\n",
    "def insta_searching(word):\n",
    "    url = \"https://www.instagram.com/explore/tags/\" + word\n",
    "    return url\n",
    "\n",
    "word = \"김채원\"\n",
    "url = insta_searching(word)\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "# 예제 4-3 HTML에서 첫번째 게시글 찾아 클릭하기\n",
    "\n",
    "# 내용 일부 수정\n",
    "def select_first(driver):\n",
    "    first = driver.find_element(By.CSS_SELECTOR, \"div._aagw\")\n",
    "    first.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "select_first(driver)\n",
    "\n",
    "def get_content(driver):\n",
    "    # ① 현재 페이지 html 정보 가져오기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # ② 본문 내용 가져오기\n",
    "    try:\n",
    "        content = soup.select('div._a9zs')[0].text\n",
    "        content = unicodedata.normalize('NFC', content)\n",
    "    except:\n",
    "        content = ' '\n",
    "    \n",
    "    # ③ 본문 내용에서 해시태그 가져오기(정규식 활용)\n",
    "    tags = re.findall(r'#[^Ws#,\\\\]+', content)\n",
    "   \n",
    "    # ④ 작성일자 정보 가져오기\n",
    "    # time class 안에 datetime이라는 항목(년월일시분초 있음)에서 10개 string만 보겠다라는 뜻\n",
    "    date = soup.select('time._a9ze')[0]['datetime'][:10] \n",
    "\n",
    "    # ⑤ 좋아요 수 가져오기\n",
    "    try:\n",
    "        like = soup.select('span.html-span')[2].text\n",
    "    except:\n",
    "        like = 0\n",
    "        \n",
    "    # ⑥ 위치정보 가져오기\n",
    "    try: \n",
    "        place = soup.select('div._aaqm')[0].text\n",
    "        place = unicodedata.normalize('NFC', place)      \n",
    "    except:\n",
    "        place = ''\n",
    "    # ⑦ 수집한 정보 저장하기\n",
    "    data = [content, date, like, place, tags]\n",
    "    return data\n",
    "\n",
    "# 예제 4-5 다음 게시글 열기\n",
    "def move_next(driver):\n",
    "    right = driver.find_element(By.CSS_SELECTOR, \"div._aaqg._aaqh\")\n",
    "    right.click()\n",
    "    time.sleep(4)\n",
    "\n",
    "# ⑤ 비어있는 변수(results)만들기\n",
    "results = [ ]\n",
    "\n",
    "\n",
    "# ⑥→⑦→⑧ 여러 게시물 수집하기\n",
    "target = 5      # 크롤링할 게시글 수\n",
    "for i in range(target):\n",
    "    # 게시글 수집에 오류 발생시(네트워크 문제 등의 이유로)  2초 대기 후, 다음 게시글로 넘어가도록 try, except 구문 활용\n",
    "    try:\n",
    "        data = get_content(driver)    # 게시글 정보 가져오기\n",
    "        results.append(data)\n",
    "        move_next(driver)\n",
    "    except:\n",
    "        time.sleep(2)\n",
    "        move_next(driver)\n",
    "    \n",
    "print(results[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.8 여러 엑셀 파일의 중복을 제거한 후 통합 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-7 크롤링 결과 엑셀 저장\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = pd.DataFrame(results, columns=['content', 'date', 'like', 'place', 'tags'])\n",
    "results_df.to_excel('./files/{}.xlsx'.format(word), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 여러 개의 저장 파일을 통합\n",
    "import pandas as pd\n",
    "\n",
    "jeju_insta_df = pd.DataFrame([])\n",
    "\n",
    "folder = './files/'\n",
    "f_list = ['이거.xlsx', '저거.xlsx','김채원.xlsx']\n",
    "\n",
    "for fname in f_list:\n",
    "    fpath = folder + fname\n",
    "    temp = pd.read_excel(fpath)\n",
    "    jeju_insta_df = pd.concat([jeju_insta_df, temp], ignore_index=True)\n",
    "\n",
    "jeju_insta_df.columns = ['content', 'date', 'like', 'place', 'tags']\n",
    "\n",
    "# 예제 4-9 중복 데이터 제거하고 저장하기\n",
    "jeju_insta_df.drop_duplicates(subset = [\"content\"] , inplace = True)\n",
    "jeju_insta_df.to_excel('./files/최종.xlsx', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
