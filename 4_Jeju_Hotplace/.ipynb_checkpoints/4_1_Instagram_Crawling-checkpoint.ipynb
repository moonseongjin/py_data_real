{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 인스타그램 크롤링 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 인스타그램 검색 결과 URL을 만들어서 접속하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-1 인스타그램 검색결과 URL을 만드는 함수\n",
    "def insta_searching(word):\n",
    "    url = \"https://www.instagram.com/explore/tags/\" + word\n",
    "    return url\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-2 selenium으로 URL 접속하기 - 1\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-2 selenium으로 URL 접속하기 - 2\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# 인스타그램 접속하기\n",
    "driver.get('https://www.instagram.com/')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-2 selenium으로 URL 접속하기 - 3\n",
    "\n",
    "# HTML 틀 바뀌어서 찾아서 변경함.\n",
    "# 인스타계정으로 로그인하기\n",
    "email = '아이디'   ### 계정 정보 수정 필요\n",
    "password = '비밀번호' ### 비번 정보 수정 필요\n",
    "\n",
    "# 인스타그램 로그인 버튼 클릭\n",
    "driver.find_element(By.CLASS_NAME, '_aa4b ').click()\n",
    "time.sleep(2)\n",
    "\n",
    "# 이메일 입력란 찾아서 값 입력\n",
    "email_input = driver.find_element(By.CLASS_NAME, '_aa4b')\n",
    "email_input.send_keys(email)\n",
    "\n",
    "# 비밀번호 입력란 찾아서 값 입력\n",
    "password_input = driver.find_elements(By.CLASS_NAME, '_aa4b')[1] \n",
    "password_input.send_keys(password)\n",
    "\n",
    "# 로그인 버튼 클릭\n",
    "login_button = driver.find_element(By.CSS_SELECTOR, 'button[type=\"submit\"]')\n",
    "login_button.click()\n",
    "\n",
    "# 일부 웹사이트에서는 로그인 버튼의 클릭 후 잠시 대기가 필요할 수 있습니다.\n",
    "time.sleep(2)  # 예시로 2초 대기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-2 selenium으로 URL 접속하기 - 4\n",
    "word = \"김채원\"\n",
    "url = insta_searching(word)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 첫 번째 게시글 열기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-3 HTML에서 첫번째 게시글 찾아 클릭하기\n",
    "\n",
    "# 내용 일부 수정\n",
    "def select_first(driver):\n",
    "    first = driver.find_element(By.CSS_SELECTOR, \"div._aabd\")\n",
    "    first.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "select_first(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 게시글 정보 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     data \u001b[38;5;241m=\u001b[39m [content, date, like, place, tags]\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m---> 35\u001b[0m get_content(driver)\n",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m, in \u001b[0;36mget_content\u001b[1;34m(driver)\u001b[0m\n\u001b[0;32m     17\u001b[0m tags \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#[^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms#,\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m]+\u001b[39m\u001b[38;5;124m'\u001b[39m, content)  \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# ④ 작성일자 정보 가져오기\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m date \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime._1o9PC.Nzb55\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m][:\u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# ⑤ 좋아요 수 가져오기\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 예제 4-4 게시글 정보 가져오기\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "def get_content(driver):\n",
    "    # ① 현재 페이지 html 정보 가져오기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # ② 본문 내용 가져오기\n",
    "    try:\n",
    "        content = soup.select('div._a9zs')[0].text\n",
    "        content = unicodedata.normalize('NFC', content)\n",
    "    except:\n",
    "        content = ' '\n",
    "    \n",
    "    # ③ 본문 내용에서 해시태그 가져오기(정규식 활용)\n",
    "    tags = re.findall(r'#[^Ws#,\\\\]+', content)\n",
    "   \n",
    "    # ④ 작성일자 정보 가져오기\n",
    "    # time class 안에 datetime이라는 항목(년월일시분초 있음)에서 10개 string만 보겠다라는 뜻\n",
    "    date = soup.select('time._a9ze')[0]['datetime'][:10] \n",
    "\n",
    "    # ⑤ 좋아요 수 가져오기\n",
    "    try:\n",
    "        like = soup.select('span.html-span')[2].text\n",
    "    except:\n",
    "        like = 0\n",
    "        \n",
    "    # ⑥ 위치정보 가져오기\n",
    "    try: \n",
    "        place = soup.select('div._aaqm')[0].text\n",
    "        place = unicodedata.normalize('NFC', place)      # 신규 추가. 2020.08.20\n",
    "    except:\n",
    "        place = ''\n",
    "    # ⑦ 수집한 정보 저장하기\n",
    "    data = [content, date, like, place, tags]\n",
    "    return data\n",
    " \n",
    "get_content(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 다음 게시글 열기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-5 다음 게시글 열기\n",
    "def move_next(driver):\n",
    "    right = driver.find_element(By.CSS_SELECTOR, \"div._aaqg._aaqh\")\n",
    "    right.click()\n",
    "    time.sleep(4)\n",
    "move_next(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.6 여러 게시글 정보 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[2024.03.03］[KCW] weverse更新Cr. @le_sserafim🫢#르세라핌 #lesserafim #lesserafimhk@sourcemusicofficial#미야와키사쿠라 #Miyawakisakura#김채원 #chaewon #kimchaewon#허윤진 #yunjin #huhyunjin#카즈하 #kazuha#홍은채 #eunchae #hongeunchae#피어나 #fearnot#imfearless #fearless #antifragile #unforgiven #easy', '2024-03-04', '920', '', ['#르세라핌 ', '#le', '#le', '#미야와키사쿠라 ', '#Miyawaki', '#김채원 ', '#chaewon ', '#kimchaewon', '#허윤진 ', '#yunjin ', '#huhyunjin', '#카즈하 ', '#kazuha', '#홍은채 ', '#eunchae ', '#hongeunchae', '#피어나 ', '#fearnot', '#imfearle', '#fearle', '#antifragile ', '#unforgiven ', '#ea']], ['🖌️2024/03/05 molak_official IG更新🌸𝐵𝐼𝐺 𝑁𝐸𝑊𝑆🌸3月17日(日)作為 #MOLAK 製作人及模特兒的#宮脇咲良 將會進行ig直播🎥 ˎˊ˗當天會在MOLAK官方instagram帳號(\\u2061 @molak_official )進行直播、請追蹤&打開提醒等待🤍將會有這個直播的獨家情報✨也會準備讓各位享受的企劃、敬請期待🌸-𝐭𝐫𝐚𝐧𝐬𝐥𝐚𝐭𝐞𝐝 𝐛𝐲 𝐋𝐄 𝐒𝐒𝐄𝐑𝐀𝐅𝐈𝐌綻放宇宙#LE_SSERAFIM #르세라핌 #ルセラフィム#SAKURA #KIMCHAEWON #HUHYUNJIN #KAZUHA #HONGEUNCHAE #사쿠라 #김채원 #허윤진 #카즈하 #홍은채 #宮脇咲良 #金采源 #許允眞 #中村一葉 #洪恩採 #LE_SSERAFIM台灣綻放宇宙站', '2024-03-05', '733', '', ['#MOLAK 製作人及模特兒的', '#宮脇咲良 將會進行ig直播🎥 ˎˊ˗當天會在MOLAK官方in', '#LE_SSERAFIM ', '#르세라핌 ', '#ルセラフィム', '#SAKURA ', '#KIMCHAE', '#HUHYUNJIN ', '#KAZUHA ', '#HONGEUNCHAE ', '#사쿠라 ', '#김채원 ', '#허윤진 ', '#카즈하 ', '#홍은채 ', '#宮脇咲良 ', '#金采源 ', '#許允眞 ', '#中村一葉 ', '#洪恩採 ', '#LE_SSERAFIM台灣綻放宇宙站']]]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = webdriver.Chrome()   \n",
    "\n",
    "# 인스타그램 접속하기\n",
    "driver.get('https://www.instagram.com/')\n",
    "time.sleep(2)\n",
    "\n",
    "# 인스타계정으로 로그인하기\n",
    "email = '01041303038'   \n",
    "password = 'moonwalk486!' \n",
    "\n",
    "# 인스타그램 로그인 버튼 클릭\n",
    "driver.find_element(By.CLASS_NAME, '_aa4b ').click()\n",
    "time.sleep(2)\n",
    "\n",
    "# 이메일 입력란 찾아서 값 입력\n",
    "email_input = driver.find_element(By.CLASS_NAME, '_aa4b')\n",
    "email_input.send_keys(email)\n",
    "\n",
    "# 비밀번호 입력란 찾아서 값 입력\n",
    "password_input = driver.find_elements(By.CLASS_NAME, '_aa4b')[1] \n",
    "password_input.send_keys(password)\n",
    "\n",
    "# 로그인 버튼 클릭\n",
    "login_button = driver.find_element(By.CSS_SELECTOR, 'button[type=\"submit\"]')\n",
    "login_button.click()\n",
    "time.sleep(3)  \n",
    "\n",
    "def insta_searching(word):\n",
    "    url = \"https://www.instagram.com/explore/tags/\" + word\n",
    "    return url\n",
    "\n",
    "word = \"김채원\"\n",
    "url = insta_searching(word)\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# 예제 4-3 HTML에서 첫번째 게시글 찾아 클릭하기\n",
    "def select_first(driver):\n",
    "    first = driver.find_element(By.CSS_SELECTOR, \"div._aabd\")\n",
    "    first.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "select_first(driver)\n",
    "\n",
    "def get_content(driver):\n",
    "    # ① 현재 페이지 html 정보 가져오기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # ② 본문 내용 가져오기\n",
    "    try:\n",
    "        content = soup.select('div._a9zs')[0].text\n",
    "        content = unicodedata.normalize('NFC', content)\n",
    "    except:\n",
    "        content = ' '\n",
    "    \n",
    "    # ③ 본문 내용에서 해시태그 가져오기(정규식 활용)\n",
    "    tags = re.findall(r'#[^Ws#,\\\\]+', content)\n",
    "   \n",
    "    # ④ 작성일자 정보 가져오기\n",
    "    # time class 안에 datetime이라는 항목(년월일시분초 있음)에서 10개 string만 보겠다라는 뜻\n",
    "    date = soup.select('time._a9ze')[0]['datetime'][:10] \n",
    "\n",
    "    # ⑤ 좋아요 수 가져오기\n",
    "    try:\n",
    "        like = soup.select('span.html-span')[2].text\n",
    "    except:\n",
    "        like = 0\n",
    "        \n",
    "    # ⑥ 위치정보 가져오기\n",
    "    try: \n",
    "        place = soup.select('div._aaqm')[0].text\n",
    "        place = unicodedata.normalize('NFC', place)      \n",
    "    except:\n",
    "        place = ''\n",
    "    # ⑦ 수집한 정보 저장하기\n",
    "    data = [content, date, like, place, tags]\n",
    "    return data\n",
    "\n",
    "# 예제 4-5 다음 게시글 열기\n",
    "def move_next(driver):\n",
    "    right = driver.find_element(By.CSS_SELECTOR, \"div._aaqg._aaqh\")\n",
    "    right.click()\n",
    "    time.sleep(4)\n",
    "\n",
    "# ⑤ 비어있는 변수(results)만들기\n",
    "results = [ ]\n",
    "\n",
    "\n",
    "# ⑥→⑦→⑧ 여러 게시물 수집하기\n",
    "target = 5      # 크롤링할 게시글 수\n",
    "for i in range(target):\n",
    "    # 게시글 수집에 오류 발생시(네트워크 문제 등의 이유로)  2초 대기 후, 다음 게시글로 넘어가도록 try, except 구문 활용\n",
    "    try:\n",
    "        data = get_content(driver)    # 게시글 정보 가져오기\n",
    "        results.append(data)\n",
    "        move_next(driver)\n",
    "    except:\n",
    "        time.sleep(2)\n",
    "        move_next(driver)\n",
    "    \n",
    "print(results[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.8 여러 엑셀 파일의 중복을 제거한 후 통합 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4-7 크롤링 결과 엑셀 저장\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = pd.DataFrame(results, columns=['content', 'date', 'like', 'place', 'tags'])\n",
    "results_df.to_excel('./files/{}.xlsx'.format(word), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 여러 개의 저장 파일을 통합\n",
    "import pandas as pd\n",
    "\n",
    "jeju_insta_df = pd.DataFrame([])\n",
    "\n",
    "folder = './files/'\n",
    "f_list = ['이거.xlsx', '저거.xlsx','김채원.xlsx']\n",
    "\n",
    "for fname in f_list:\n",
    "    fpath = folder + fname\n",
    "    temp = pd.read_excel(fpath)\n",
    "    jeju_insta_df = pd.concat([jeju_insta_df, temp], ignore_index=True)\n",
    "\n",
    "jeju_insta_df.columns = ['content', 'date', 'like', 'place', 'tags']\n",
    "\n",
    "# 예제 4-9 중복 데이터 제거하고 저장하기\n",
    "jeju_insta_df.drop_duplicates(subset = [\"content\"] , inplace = True)\n",
    "jeju_insta_df.to_excel('./files/최종.xlsx', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
